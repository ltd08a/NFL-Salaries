{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40648680-58c2-416e-b17b-44fafac850cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a39ac87b-efbc-4c05-8c93-7a4ee018efa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty list to hold individual DataFrames\n",
    "df_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75828337-4ac4-4881-9de0-5644328f6d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate URL for scraping\n",
    "def gen_url(start_year, end_year):\n",
    "    \"\"\"\n",
    "    Generates a Wikipedia URL for NFL playoffs based on the start and end years.\n",
    "\n",
    "    Parameters:\n",
    "    start_year (int): The start year of the NFL season.\n",
    "    end_year (int): The end year of the NFL season.\n",
    "\n",
    "    Returns:\n",
    "    str: The URL for the Wikipedia page of the NFL playoffs for that season.\n",
    "    \"\"\"\n",
    "    url_template = 'https://en.wikipedia.org/wiki/{start_year}%E2%80%93{end_year}_NFL_playoffs'\n",
    "    \n",
    "    return url_template.format(start_year=start_year, end_year=str(end_year)[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "865c9585-3b2b-43ff-a0c3-7b1a9ee7a5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for 2011\n",
      "Fetching data for 2012\n",
      "Fetching data for 2013\n",
      "Fetching data for 2014\n",
      "Fetching data for 2015\n",
      "Fetching data for 2016\n",
      "Fetching data for 2017\n",
      "Fetching data for 2018\n",
      "Fetching data for 2019\n",
      "Fetching data for 2020\n",
      "Fetching data for 2021\n",
      "Fetching data for 2022\n",
      "Fetching data for 2023\n"
     ]
    }
   ],
   "source": [
    "# Loop through year range and scrape data using the gen_url function\n",
    "for year in range(2011, 2024):\n",
    "    url = gen_url(year, year + 1)\n",
    "    print(f'Fetching data for {year}')\n",
    "    \n",
    "    # Send a GET request to fetch the webpage content\n",
    "    response = requests.get(url)\n",
    "    webpage = response.content\n",
    "\n",
    "    # Parse through the webpage content with Beautiful Soup\n",
    "    soup = BeautifulSoup(webpage, 'html.parser')\n",
    "\n",
    "    # Select the target table\n",
    "    table = soup.find('table', class_ = 'wikitable')\n",
    "\n",
    "    # Check if table exists\n",
    "    if table:\n",
    "        # Locate all rows in the table\n",
    "        rows = table.find_all('tr')\n",
    "\n",
    "        # Initialize a list to hold the current year's team names\n",
    "        year_data = []\n",
    "\n",
    "        # Iterate over rows starting with index 2\n",
    "        for row in rows[2:]:\n",
    "            cells = row.find_all('td') # Find all elements in the row\n",
    "            cell_texts = [cell.text.strip() for cell in cells] # Extract and strip the text from each cell\n",
    "\n",
    "            # Extract the team names from the text\n",
    "            for item in cell_texts[1:]: # Skip first element\n",
    "                full_name = item.split('(')[0].strip() # Extract team name before parenthesis\n",
    "                parts = full_name.split() # Split name by spaces\n",
    "                team_name = parts[-1] # Extract the last part of team name\n",
    "\n",
    "                # Append the year and team name to the year's data list\n",
    "                year_data.append({'year': year, 'team': team_name})\n",
    "\n",
    "        # Convert the current year's data to a DataFrame and add it to the list of DataFrames\n",
    "        df_list.append(pd.DataFrame(year_data))\n",
    "        \n",
    "    else:\n",
    "        print(f'No table found for {year}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "765380c5-18ab-4405-855c-8c56efea23cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     year        team\n",
      "0    2011    Patriots\n",
      "1    2011     Packers\n",
      "2    2011      Ravens\n",
      "3    2011       49ers\n",
      "4    2011      Texans\n",
      "..    ...         ...\n",
      "127  2023       Lions\n",
      "128  2023  Buccaneers\n",
      "129  2023      Eagles\n",
      "130  2023        Rams\n",
      "131  2023     Packers\n",
      "\n",
      "[132 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the current year's data to a DataFrame and add it to the list of DataFrames\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae8d10ab-cd95-46b4-aa55-56d4b67764e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV file\n",
    "df.to_csv('nfl_playoff_teams.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
